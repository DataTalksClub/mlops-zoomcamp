{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2194c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd5780",
   "metadata": {},
   "source": [
    "## Homework 1\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563d625",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. How many records are there?\n",
    "\n",
    "* 1054112\n",
    "* 1154112 &check;\n",
    "* 1254112\n",
    "* 1354112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3396376b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1154112, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/fhv_tripdata_2021-01.parquet')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eabd95",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes. \n",
    "\n",
    "What's the average trip duration in January?\n",
    "\n",
    "* 15.16\n",
    "* 19.16 &check;\n",
    "* 24.16\n",
    "* 29.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f64c48b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.167224093791006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df.duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1153407",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers. \n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "How many records did you drop? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93754069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.duration >= 1) & (df.duration <= 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c7c7c",
   "metadata": {},
   "source": [
    "## Q3. Missing values\n",
    "\n",
    "The features we'll use for our model are the pickup and dropoff location IDs. \n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "What's the fractions of missing values for the pickup location ID? I.e. fraction of \"-1\"s after you filled the NAs.\n",
    "\n",
    "* 53%\n",
    "* 63%\n",
    "* 73%\n",
    "* 83%  &check;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daff64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352732770722617"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['PUlocationID', 'DOlocationID']] = df[['PUlocationID', 'DOlocationID']].fillna(value=-1)\n",
    "df.PUlocationID.value_counts(normalize=True)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed4364",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model. \n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer \n",
    "* Get a feature matrix from it\n",
    "\n",
    "What's the dimensionality of this matrix? (The number of columns).\n",
    "\n",
    "* 2\n",
    "* 152\n",
    "* 352\n",
    "* 525 &check;\n",
    "* 725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65338a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109826, 525)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = df[['PUlocationID', 'DOlocationID']].astype(str).to_dict(orient='records')\n",
    "dv = DictVectorizer()\n",
    "X = dv.fit_transform(dicts)\n",
    "y = df.duration.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11902b",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model. \n",
    "\n",
    "* Train a plain linear regression model with default parameters \n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "What's the RMSE on train?\n",
    "\n",
    "* 5.52\n",
    "* 10.52 &check;\n",
    "* 15.52\n",
    "* 20.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5b05ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.528519429348535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "y_pred = lr.predict(X)\n",
    "mean_squared_error(y, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c906adf",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021). \n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "* 6.01\n",
    "* 11.01  &check;\n",
    "* 16.01\n",
    "* 21.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9cdf77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.014286123189528"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_parquet('./data/fhv_tripdata_2021-02.parquet')\n",
    "df_valid['duration'] = df_valid.dropOff_datetime - df_valid.pickup_datetime\n",
    "df_valid.duration = df_valid.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "df_valid = df_valid[(df_valid.duration >= 1) & (df_valid.duration <= 60)]\n",
    "df_valid.loc[:, ['PUlocationID', 'DOlocationID']] = df_valid[['PUlocationID', 'DOlocationID']].fillna(value=-1)\n",
    "dicts_valid = df_valid[['PUlocationID', 'DOlocationID']].astype(str).to_dict(orient='records')\n",
    "\n",
    "X_valid = dv.transform(dicts_valid)\n",
    "y_valid = df_valid.duration.values\n",
    "y_pred = lr.predict(X_valid)\n",
    "mean_squared_error(y_valid, y_pred, squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
