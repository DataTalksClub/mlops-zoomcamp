{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190d03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3e702",
   "metadata": {},
   "source": [
    "### FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899473d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "\n",
    "    \"\"\"\n",
    "    This function reads a dataset from a Parquet file and returns a DataFrame.\n",
    "\n",
    "    Args:\n",
    "    filename: The path to the Parquet file.\n",
    "\n",
    "    Returns:\n",
    "    A DataFrame containing the data from the Parquet file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Import the necessary modules.\n",
    "    #import pandas as pd\n",
    "\n",
    "    # Check if the filename is a valid path to a Parquet file.\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(\"The file {} does not exist.\".format(filename))\n",
    "\n",
    "    # Read the data from the Parquet file.\n",
    "    try:\n",
    "        data = pd.read_parquet(filename)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occurred while reading the file {}: {}\".format(filename, e))\n",
    "\n",
    "    # Calculate the trip duration.\n",
    "    data['trip_duration'] = data.tpep_dropoff_datetime - data.tpep_pickup_datetime\n",
    "\n",
    "    # Convert the trip duration to minutes.\n",
    "    data['trip_duration'] = data.trip_duration.apply(lambda x: x.total_seconds()/60)\n",
    "\n",
    "    # Filter the data to include only trips that lasted between 1 and 60 minutes.\n",
    "    data = data[(data['trip_duration'] >= 1) & (data['trip_duration'] <= 60)]\n",
    "\n",
    "    # Convert the pickup and dropoff location IDs to strings.\n",
    "    data[['PULocationID','DOLocationID']] = data[['PULocationID','DOLocationID']].astype(str)\n",
    "\n",
    "    # Return the DataFrame.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868c0b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "\n",
    "    \"\"\"\n",
    "    This function prepares the data for machine learning.\n",
    "\n",
    "    Args:\n",
    "    data: The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "    A tuple of NumPy arrays containing the features and target values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the data is a DataFrame.\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise TypeError(\"The data must be a DataFrame.\")\n",
    "\n",
    "    # Create a list of the categorical columns.\n",
    "    cat_cols = ['PU_DO']\n",
    "\n",
    "    # Convert the categorical columns to strings.\n",
    "    data[cat_cols] = data[cat_cols].astype(str)\n",
    "\n",
    "    # Create a list of the numerical columns.\n",
    "    num_cols = ['trip_distance']\n",
    "\n",
    "    # Convert the numerical columns to NumPy arrays.\n",
    "    num_data = data[num_cols].values\n",
    "\n",
    "    # Create a list of all the columns.\n",
    "    global cols\n",
    "    cols = cat_cols + num_cols\n",
    "\n",
    "    # Convert the DataFrame to a dictionary format.\n",
    "    global train_dicts\n",
    "    train_dicts = data[cat_cols].to_dict(orient='records')\n",
    "\n",
    "    # Create a DictVectorizer object.\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    # Fit the DictVectorizer object to the data.\n",
    "    global x\n",
    "    x = dv.fit_transform(train_dicts)\n",
    "\n",
    "    # Get the target values.\n",
    "    global y \n",
    "    y = data['trip_distance'].values\n",
    "\n",
    "    # Return the features and target values.\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c74bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model):\n",
    "\n",
    "    \"\"\"\n",
    "    This function trains a machine learning model on the given data.\n",
    "\n",
    "    Args:\n",
    "    x: The training data.\n",
    "    y: The target values for the training data.\n",
    "    model: The machine learning model to train.\n",
    "\n",
    "    Returns:\n",
    "    The trained machine learning model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Import the necessary modules.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Split the data into a training set and a test set.\n",
    "    global y_train\n",
    "    X_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # Choose the model to train.\n",
    "    if model == 'LinearRegression':\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        model = LinearRegression()\n",
    "    elif model == 'Lasso':\n",
    "        from sklearn.linear_model import Lasso\n",
    "        model = Lasso()\n",
    "    else:\n",
    "        from sklearn.linear_model import Ridge\n",
    "        model = Ridge()\n",
    "\n",
    "    # Fit the model to the training data.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the target values for the test data.\n",
    "    global pred\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate the mean squared error and accuracy score of the predictions.\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    score = model.score(x_test,pred)\n",
    "\n",
    "    # Print the mean squared error.\n",
    "    print(f'Mean squared error score: {mse}')\n",
    "    print(f'accuracy score: {score}')\n",
    "\n",
    "    # Return the trained model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837a92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9c72cd8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a974f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421440, 2918187)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in dataset\n",
    "df_train = read_data('yellow_tripdata_2022-01.parquet')\n",
    "df_val = read_data('yellow_tripdata_2022-02.parquet')\n",
    "\n",
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930e549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80de5056",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e39f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e250c01",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f03b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] \n",
    "numerical = ['trip_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7758c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88309151",
   "metadata": {},
   "source": [
    "### DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa4825e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['PU_DO'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprep_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mprep_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     18\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPU_DO\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Convert the categorical columns to strings.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m data[cat_cols] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create a list of the numerical columns.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m num_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_distance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['PU_DO'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "prep_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c065d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = df_train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ef72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56504ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a0eda",
   "metadata": {},
   "source": [
    "### MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols\n",
    "train(x,y,'LinearRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ffcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "sb.histplot(y_train,label=\"actual_values\",kde=True,stat=\"density\",\n",
    "            kde_kws=dict(cut=3), bins=50,alpha=.4, edgecolor=(1, 1, 1, 0.4))\n",
    "sb.histplot(pred,label=\"predicted_values\",kde=True,stat=\"density\",\n",
    "            kde_kws=dict(cut=3), bins=50,alpha=.4, edgecolor=(1, 1, 1, 0.4))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso regression\n",
    "train(x,y,'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge regression\n",
    "train(x,y,'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfcd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl','wb') as fb:\n",
    "    joblib.dump(model,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
