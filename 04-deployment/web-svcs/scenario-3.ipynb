{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Multiple data scientists working on multiple ML models\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: yes, remote server (EC2).\n",
    "* Backend store: postgresql database.\n",
    "* Artifacts store: s3 bucket.\n",
    "\n",
    "The experiments can be explored by accessing the remote server.\n",
    "\n",
    "The exampe uses AWS to host a remote server. In order to run the example you'll need an AWS account. Follow the steps described in the file `mlflow_on_aws.md` to create a new AWS account and launch the tracking server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlflow.tracking import MlflowClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/22 20:17:01 INFO mlflow.tracking.fluent: Experiment with name 'green-taxi-duration' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-gansi/1', creation_time=1719067621678, experiment_id='1', last_update_time=1719067621678, lifecycle_stage='active', name='green-taxi-duration', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"AWS_PROFILE\"] = \"ArunG\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"http://127.0.0.1:5000\"\n",
    "mlflow.set_tracking_uri(TRACKING_SERVER_HOST)\n",
    "mlflow.set_experiment(\"green-taxi-duration\")\n",
    "\n",
    "#TRACKING_SERVER_HOST = \"ec2-13-60-29-159.eu-north-1.compute.amazonaws.com\" # fill in with the public DNS of the EC2 instance\n",
    "#mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000' http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\", TRACKING_SERVER_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename: str):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dictionaries(df: pd.DataFrame):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "dict_train = prepare_dictionaries(df_train)\n",
    "dict_val = prepare_dictionaries(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9531)\t1.0\n",
      "  (0, 13220)\t1.01\n",
      "  (1, 2841)\t1.0\n",
      "  (1, 13220)\t2.53\n",
      "  (2, 9317)\t1.0\n",
      "  (2, 13220)\t1.12\n",
      "  (3, 3061)\t1.0\n",
      "  (3, 13220)\t1.99\n",
      "  (4, 11595)\t1.0\n",
      "  (4, 13220)\t0.45\n",
      "  (5, 6114)\t1.0\n",
      "  (5, 13220)\t12.19\n",
      "  (6, 7220)\t1.0\n",
      "  (6, 13220)\t3.39\n",
      "  (7, 11511)\t1.0\n",
      "  (7, 13220)\t6.69\n",
      "  (8, 11347)\t1.0\n",
      "  (8, 13220)\t2.34\n",
      "  (9, 11391)\t1.0\n",
      "  (9, 13220)\t5.48\n",
      "  (10, 9469)\t1.0\n",
      "  (10, 13220)\t0.9\n",
      "  (11, 11267)\t1.0\n",
      "  (11, 13220)\t2.08\n",
      "  (12, 375)\t1.0\n",
      "  :\t:\n",
      "  (73895, 13220)\t12.64\n",
      "  (73896, 9873)\t1.0\n",
      "  (73896, 13220)\t4.99\n",
      "  (73897, 11569)\t1.0\n",
      "  (73897, 13220)\t4.13\n",
      "  (73898, 177)\t1.0\n",
      "  (73898, 13220)\t5.05\n",
      "  (73899, 10373)\t1.0\n",
      "  (73899, 13220)\t5.33\n",
      "  (73900, 3378)\t1.0\n",
      "  (73900, 13220)\t5.18\n",
      "  (73901, 1531)\t1.0\n",
      "  (73901, 13220)\t17.13\n",
      "  (73902, 5716)\t1.0\n",
      "  (73902, 13220)\t18.18\n",
      "  (73903, 12189)\t1.0\n",
      "  (73903, 13220)\t17.63\n",
      "  (73904, 8719)\t1.0\n",
      "  (73904, 13220)\t18.36\n",
      "  (73905, 11397)\t1.0\n",
      "  (73905, 13220)\t2.5\n",
      "  (73906, 3014)\t1.0\n",
      "  (73906, 13220)\t14.48\n",
      "  (73907, 600)\t1.0\n",
      "  (73907, 13220)\t1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python310\\envs\\mldeploy\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'n_estimators': 100, 'min_samples_leaf': 10, 'random_state': 0} 6.7558229919200725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python310\\envs\\mldeploy\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "d:\\Program Files\\Python310\\envs\\mldeploy\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "   params = dict(max_depth=20, n_estimators=100, min_samples_leaf=10, random_state=0)\n",
    "   mlflow.log_params(params)\n",
    "\n",
    "   dv = DictVectorizer()\n",
    "   model = RandomForestRegressor(**params, n_jobs=-1)\n",
    "\n",
    "   X_train = dv.fit_transform(dict_train)\n",
    "   \n",
    "   model.fit(X_train,y_train)\n",
    "    \n",
    "   X_val = dv.transform(dict_val)\n",
    "   y_pred = model.predict(X_val)\n",
    "\n",
    "   rmse = mean_squared_error(y_pred, y_val, squared=False)\n",
    "   print(params, rmse)\n",
    "   mlflow.log_metric('rmse', rmse)\n",
    "\n",
    "   mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "    \n",
    "   with open('dict_vectorizer.bin','wb') as f_out:\n",
    "      pickle.dump(dv,f_out)\n",
    "    \n",
    "   mlflow.log_artifact('dict_vectorizer.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '06b0431d472841d899a8cbc5a8fc52a1'\n",
    "client = MlflowClient(f\"http://{TRACKING_SERVER_HOST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = client.download_artifacts(run_id=RUN_ID, path='dict_vectorizer.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARUNGA~1\\AppData\\Local\\Temp\\tmpb9pfs7o5\\dict_vectorizer.bin\n"
     ]
    }
   ],
   "source": [
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exp-tracking-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
